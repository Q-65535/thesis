\chapter{绪论}
\section{智能体简介}
%智能体
随着近年来人工智能领域的高速发展，计算系统的智能性受到越来越多人的重视。智能体(Agent)是嵌于特定环境中能够自主行动 以实现给定设计目标的个体\cite{DBLP:books/daglib/0023784}。多智能体系统 Multi-Agent System, MAS）\cite{DBLP:books/daglib/0023784}通过智能体间的交互实现分布式智能，能够用于解决单个智能体难以或者无法解决的问题，是当前人工智能领域的 研究热点之一。多智能体相关的研究成果已经广泛应用于工业制造\cite{biernatzki2004agent} 、城市交通等重要领域\cite{DBLP:journals/tits/ChenC10}。

%BDI智能体
在当前针对智能体与多智能体系统的研究中出现了多种用于实现自主智能体的智能体体系结构，包括慎思型结构、反应型结构以 及混合型结构\cite{DBLP:conf/atal/2000, DBLP:journals/ker/WooldridgeJ95}等。
% BDI
其中，基于心理学实践推理(Practical Reasoning)\cite{bratman1987intention}的 Belief-Desire-Intention-based (BDI)模型\cite{DBLP:conf/atal/GeorgeffPPTW98} 是当前学术界应用和研究最多的智能体体系结构之一。
%
采用 BDI模型实现的智能体（BDI 智能体）使用信念（Belief）、愿望 （Desire）以及意图（Intention）等概念来表示自身的心智状态，并通过实践推理来决定下一步应该采取的行动。
%
智能体的信念指的是智能体对其所处环境以及自身的认知，即智能体相信什么；愿望（又被称为目标）指的是智能体想要达到的世界状态的集合。智能 体通过执行计划（Plan）来实现其给定设计目标。计划由 顺序执行的一系列步骤组成。每个步骤可能是能够改变当前世界状 态的基本动作，或者是需要由智能体实现的子目标。
%
当智能体选择 某一特定计划来实现其给定目标时，该计划未执行的部分被称为实 现该目标的意图，即智能体承诺为了实现目标而执行的步骤。

到目前为止已有许多基于BDI智能体架构的编程语言和平台被提出并广泛应用。最早基于BDI架构的智能体系统是Procedure Reasoning Systems(PRS)，其被开发用于航空领域\cite{DBLP:conf/aaai/GeorgeffL87}以及网络交通领域\cite{DBLP:conf/aaaiss/Wobcke07}。AgentSpeak(L)\cite{DBLP:conf/maamaw/Rao96},一种抽象的BDI智能体编程语言，主要目的是帮助人们理解BDI架构在实际中的应用（例如PRS）与BDI架构理论模型直接的关系。Jason\cite{bordini2007programming}是一门基于AgentSpeak(L)开发的实用性语言，其语言的底层实现基于JAVA，有着很好的跨平台特性。除此以外，还有许多其他基于BDI架构的语言和平台，例如2APL\cite{DBLP:journals/aamas/Dastani08}，3APL\cite{DBLP:books/sp/map2005/DastaniRM05}以及JACK\cite{DBLP:books/sp/map2005/Winikoff05}。

目标与意图是BDI智能体的核心。在 BDI 模型中，一个目标通 常对应有多个不同的实施计划以应对不同的环境状态。智能体需要 选择执行其中的一个计划来实现其自身目标。该问题被称为 BDI 智 能体的计划选择（Plan Selection）问题\cite{yao2017robust}。在许多实际问题中， BDI 智能体都会被同时赋予多个目标进而产生多个并行意图。此 时，BDI 智能体需要决定下一步应该执行哪一个意图。该问题被称 为 BDI 智能体的意图选择(Intention Selection)问题\cite{yao2017robust}。在\cite{DBLP:conf/emas/Castle-GreenDL20}中，智能体的计划选择与意图选择被称为智能体慎思过程中的意图 进展问题（Intention Progression Problem， IPP），即 BDI 智能 体在每一个慎思周期中都需要选择其下一步需要执行的意图，如果 被选择的意图的下一步是子目标，那么BDI智能体还需要选择实现目标所需要的计划。


IPP是BDI智能体研究中的一个关键问题，任意地进行意图进 展可能会导致不同意图间的冲突，例如，智能体$\alpha$有两个目标：前往地点A和购买电池；前往地点A可由两个计划实现：行走前往和打车前往。若$\alpha$先选择打车前往 A，则可能由于打车的资金花费而导致后续没钱购买电池，而选择行走前往则不会造成该冲突。
\section{研究意义}
在现有的对BDI智能体意图进展问题的研究中，许多实用的意图调度方法被提出用以提高智能体实现目标的能力。例如，基于 Summary Information 的方法 SI\cite{DBLP:journals/jar/ThangarajahP11}从子目标和子计划出发总结出 实现上层目标所需的资源与条件，并根据总结信息来规避智能体间 可能出现的冲突或者通过合并相同步骤来减少资源开销。基于 Coverage 概念的方法 CB\cite{DBLP:journals/aamas/WatersPS15,DBLP:conf/atal/WatersPS14,DBLP:conf/aamas/ThangarajahSP12}提出了Coverage概念用以定义满足计划前提条件的难易度，在意图选择时优先选择执行当前满足条件且具有高难度计划的意图，以免错失执行机会。基于 MCTS 的调度机制\cite{DBLP:conf/aaai/YaoLT16,DBLP:conf/atal/YaoL16,DBLP:conf/ecai/YaoLT14,DBLP:conf/atal/Yao21,DBLP:conf/ijcai/Yao20,DBLP:conf/ecai/YaoLT16}利用随机模拟和抽样构建搜索树来指导agent的做出最优决策以避免冲突并高效利用协同效应。

% 社会模拟场景
BDI智能体在社会模拟场景中也有广泛的应用\cite{DBLP:conf/ijcai/SinghSPJ11}，其类人的内部心智状态表示以及行为推理方式使其能够灵活地适应于多种社会模拟场景。BDI智能体程序自然假设环境是动态的，能够在不同情 况下实时选择合适的方式实现目标；另外，BDI 智能体有能力处理执行失败的情况，当某个计划执行失败时，其可以通过失败恢复机 制重新考虑如何实现当前目标。此思考与运行机制使得BDI智能体拥有高度适应性与灵活性，并且与人类操作方式非常类似，这使其有能够合理应用于社会模拟场景。

% Norm
在某些社会模拟场景中，环境是开放的，不同类型的智能体可以随意地选择离开或是加入，它们的行为能力与目标也不尽相同。这些特性使得开放多智能体系统的运行状况与结果难以预测与控制。当某些智能体实施恶意行为时，其可能会对其它正常运行的智 能体甚至整个系统造成严重损害。为了保证环境的可控性与稳定性，norm的概念被提出作为管控智能体行为的一种方式\cite{DBLP:journals/mags/SavarimuthuC11}，其对智能体的某些行为在一定条件下加以某些的约束，用于确保智能体 在环境中的合理、合规地运作。norm 通常定义了系统中智能体‘道义’方面的行为准则。Norm 以义务（Obligation）来规范智能体在 某些情景下应该去做什么，例如在超市里，智能体应该付完钱之后再带着商品离开；norm以许可（Permission）来规范智能体在某些 场景下可以做什么，例如智能体在环境中移动是被许可的；norm也可以禁令（Prohibition）来规范智能体在某些场景下不能去做什么，例如在开放多智能体系统中攻击或伤害其它智能体是被禁止的。Norm对智能体的约束可能会对智能体实现目标的过程造成阻碍，或是限制智能体某些特定的实现目标的方式。盲目的、不考虑 norm的智能体运行机制势必会导致低效的执行效果。例如，当一个智能体正常前往某个目的地需要过马路时，它需要考虑交通规范norm对其的约束：在红灯时不能过马路（即使它有能力这么做，否则，将受到罚款。另一方面，若智能体需要尽快到达目的地时（例如救火），其可以考虑违反交通规范norm，优先实现更为重要的目标，若智能体没有考虑norm对其实现目标的影响的能力，则无法做出合理的决策。因此，一个高效的、能够对 norm进行合理考虑的智能体意图调度机制对构建适应性强、运行在norm作用环境下的智能体有十分重要的意义。

规范实践推理（Normative Practical Reasoning，NPR）指的是智能体在实践推理的过程中考虑norm对其影响。在其相关研究领域中，研究者们提出了多种考虑norm的智能体决策方法，例如：基于逻辑推理型机制\cite{DBLP:conf/agents/BroersenDHHT01,DBLP:conf/ijcai/KollingbaumN03}，使用逻辑推理解析消解norm相关冲突；基于优先级机制\cite{DBLP:conf/aamas/AlechinaDL12,DBLP:conf/dalt/LeePLDA14}，使用优先级排序方式确定 norm 与 目标的重要性；基于价值评估机制\cite{DBLP:journals/eaai/MeneguzziROVL15}，在norm约束下对计划进行数值化评估，确定其执行收益。

然而，这些解决 NPR 问题的方法都没有考虑到意图进展问题中 多意图并发执行下的意图调度问题，使得其无法高效地在 norm 约束 下高效实现目标，同时，现有的意图调度算法也没有考虑到社会模 拟场景中 norm 规范对智能体的影响。

虽然 BDI 智能体在社会模拟场景中得到广泛应用，但是在智能 体目标的表示与推理机制方面，以往相关研究大多聚焦于实现型目 标，而没有考虑到维持型目标。维持型目标定义了某些情况下以维 持某个状态一段时间为目标，例如火星探测器需要在勘探过程中维 持电量在某一数值之上，以确保其能够在勘探之后顺利返回基地补 充电量。Dastani等人\cite{DBLP:conf/atal/DastaniRM06} 描述了维持型目标，刻画了智能体对维持某 一个状态需求的基本模型。然而，现有意图调度算法大多仅考虑了 实现型目标，即到达某个世界状态，而没有考虑维持某个世界状态 的维持型目标。目前仅有的对维持型目标加入考虑的意图调度算法\cite{DBLP:conf/atal/DuffHT06,DBLP:journals/ci/DuffTH14,DBLP:conf/dalt/HindriksR07}并没有考虑到多意图并行交错执行对维持型目标的影响。

在真实社会场景中，复杂多变的环境往往需要智能体有更强的功能性与灵活性，例如要求智能体同时处理各种类型的目标以及norm。然而现有研究大多都仅针对解决某一特定的需求或增强某一特定的功能，在维持型目标的研究中没有考虑到norm的影响，另一方面在norm的相关研究中没有考虑到其他更加复杂种类的目标。这种现状一定程度上限制了BDI智能体的一般性，通用性。
\section{研究价值}
% 问题
根据上述对研究背景和意义的介绍与分析，得知当前在BDI智能体决策研究领域有如下问题：
\begin{enumerate}
  \item 现有关于智能体决策的研究大多针对实现型目标，而极少考虑到维持型目标，特别是实现型和维持型目标共存的情况。另一方面，在针对维持型目标的研究中没有考虑到多意图并发执行的问题。
  \item 现有的关于NPR研究中没有考虑到多意图并发执行的情况，意图之间的交错执行与相互影响被忽略。这使得智能体无法在norm约束下高效实现多个目标。另一方面，现有的关于多意图调度算法中没有考虑到norm对智能体的影响。
  \item 维持型目标与norm共存的情况再模拟社会场景中并不少见，然而现有研究大多仅针对解决一个方面的问题（或维持型目标或norm），缺乏一般性。
\end{enumerate}

%
为了解决上述问题，本文充分研究了社会仿真模拟场景下智能体的行为决策相关技术，并基于随机采样模拟和时序逻辑提出一系列BDI智能体意图调度方法：
\begin{itemize}
  \item
针对问题1：本文将研究并实现对维持型目标全面支持的智能体意图调度方法，该方法在SA的基础上进行拓展，在决策时加入对维持型目标的考虑，使得智能体能够在意图调度过程中考虑到维持型目标，拓展智能体的适用领域。根据智能体对环境的确定性不同，该方法考虑了主动的维持型目标（在维持型目标被破坏之前尝试修复操作）以及被动的维持型目标（在维持型目标被破坏之后尝试修复操作），以适应不同的应用场景。
  \item
针对问题2：为了实现 norm 约束下的意图调度算法，本文将对智能体的norm约束问题模型，多目标交错执行触发 norm 问题以及 norm 对智能体决策的影响问题展开研究，提出norm约束下的意图决策方法，该方法在SA算法的基础上进行拓展，对其运行时的多个阶段进行修改，加入对norm的考虑，实现智能体高效地在 norm 约束环境中并行实现多目标能力，提高智能体的适用性。
  \item
针对问题3：本文在对前两个问题的研究基础之上，提出基于时序逻辑（Linear Temporal Logic，LTL）的意图调度算法，使得智能体可以同时处理norm与维持型目标。此外，由于时序逻辑的一般性，使得该方法有较强的拓展性，其可适用范围不限于norm与维持型目标，而可被应用于用户自定义类型的目标（例如条件限制的维持型目标或实现型目标）或是其他场景约束。
\end{itemize}
%
\section{论文主要内容及章节安排}
本文的章节安排如下。第二章首先介绍智能体的基本背景概念，再引出一种热门的智能体架构-BDI智能体架构；其次，对现有相关研究内容进行文献述评，分析不同研究所提出方法的特点以及局限性；然后对BDI智能体的相关概念如信念、意图等进行规范定义，并介绍使用目标计划树的数据结构表示智能体意图的方法；最后，基于目标计划树模型对研究问题，即意图进展问题进行规范形式化定义。

第三章介绍本研究所基于的核心算法蒙特卡洛树搜索（Monte-Carlo Tree Search，MCTS）。并对其算法进行细致解释。最后，介绍MCTS在目标计划树模型下的具体应用：\SA 算法，为后续章节中的算法解释提供基础。

第四章提出一种基于\SA 的意图调度算法\SAM ，\SAM 支持同时对实现型和维持型目标的调度。其中维持型目标考虑到了在第\ref{background}中提到的被动维持型目标和主动维持型目标。另外，基于模拟火星探测器场景，对\SAM 的性能在动态和静态环境下进行了实验分析，并与Duff等人提出的PMG\cite{DBLP:conf/atal/DuffHT06}算法进行了比较，实验结果表明\SAM 的表现相对PMG有显著优势。

第五章提出一种基于\SA 的意图调度算法\SAN ，\SAN 支持在norm约束下对智能体意图进行调度。和对\SAM 的性能评估方式类似，在实验部分，对\SAN 的性能在动态和静态环境下进行了实验分析，并与Meneguzzi等人提出的v-BDI\cite{}算法进行了比较，实验结果表明SAN的性能相较于v-BDI有显著优势。

第六章提出一种基于LTL的智能体目标和norm的表示方法，并将其与\SA 算法结合，提出一种同时支持实现型目标、维持型目标以及norm的意图调度算法\SAT。该章实验部分对\SAT 的性能表现在不同的资源储备量下进行了分析，并与Duff等人提出的PMG\cite{DBLP:conf/atal/DuffHT06}算法和Meneguzzi等人提出的v-BDI算法进行了比较，实验结果表明\SAT 的性能表现相对PMG和v-BDI有显著优势。

第七章对本文研究内容进行总结并对现有研究的不足之处进行分析，并在最后对未来可能的研究方向和研究热点进行展望。
